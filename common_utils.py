import pandas as pdfrom gensim.models import KeyedVectorsfrom sklearn.model_selection import train_test_splitimport redef clean_str(string):    """    Tokenization/string cleaning.    """    string = re.sub(r"[^A-Za-z0-9(),!?\'\`]", " ", string)    string = re.sub(r"\'s", " \'s", string)    string = re.sub(r"\'ve", " \'ve", string)    string = re.sub(r"n\'t", " n\'t", string)    string = re.sub(r"\'re", " \'re", string)    string = re.sub(r"\'d", " \'d", string)    string = re.sub(r"\'ll", " \'ll", string)    string = re.sub(r",", " , ", string)    string = re.sub(r"!", " ! ", string)    string = re.sub(r"\(", " ( ", string)    string = re.sub(r"\)", " ) ", string)    string = re.sub(r"\?", " ? ", string)    string = re.sub(r"\s{2,}", " ", string)    # string = string.lower()    return string.strip()  # .lower() word2vec is case sensitivedef read_word2vec_model(filepath):    '''        Parameters    ----------    filepath : File path where the word2vec pretrained model is stored.    Returns    -------    Pretrained word2vec Model.    '''    return KeyedVectors.load(filepath)    def read_data(filepath):    '''        Parameters    ----------    filepath : Data where the MIMIC-III dat is stored.    Returns    -------    Return dataframe of MIMIC-III database with Clinical notes.    '''    data_df = pd.read_csv(filepath)    data_df = data_df[data_df.category == 'Discharge summary']    return data_df    def read_label(filepath):    return pd.read_csv(filepath)    def join_data_with_label(data, label):    label_grouped_df = label.groupby(        ['Hospital.Admission.ID', 'subject.id', 'chart.time', 'cohort']).agg('min').reset_index()    data_merge = pd.merge(        data,         label_grouped_df,         how='inner',         left_on=['subject_id', 'hadm_id'],         right_on=['subject.id', 'Hospital.Admission.ID']    )    patient_summary = data_merge.groupby(['subject.id', 'Hospital.Admission.ID'])['text'].agg(lambda x: ' '.join(x)).reset_index()    patient_summary['text'] = patient_summary.apply(lambda x: clean_str(x['text']), axis = 1)    patient_summary['summary_token'] = patient_summary.apply(lambda x: x['text'].split(), axis=1)    return pd.merge(label_grouped_df, patient_summary, on = ['subject.id', 'Hospital.Admission.ID'])def train_test_val_split(dataset, train_per, test_per, val_per):    # return train_test_split(X, Y, test_size=test_per, random_state=1, shuffle=False)    inter_dataset, test_dataset = train_test_split(dataset, test_size=test_per, random_state=1, shuffle=False)    train_dataset, val_dataset = train_test_split(inter_dataset, test_size = val_per / (train_per + val_per), random_state=1, shuffle=False)    return train_dataset, val_dataset, test_dataset    